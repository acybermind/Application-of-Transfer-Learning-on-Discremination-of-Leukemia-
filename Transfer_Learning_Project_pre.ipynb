{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47e97caf5b68455886482a8f7550236f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c999b6ca64754464af78adf60f2de7a9",
              "IPY_MODEL_246f7bcacba7412c8f6ae94b1a02380b",
              "IPY_MODEL_4b24ec443a674c398d599bfd4a019033"
            ],
            "layout": "IPY_MODEL_e86d6914bbf24d5ba2e4bf5eac05bd02"
          }
        },
        "c999b6ca64754464af78adf60f2de7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c9a2cd9d0d42c3a1a09a55dc76173f",
            "placeholder": "​",
            "style": "IPY_MODEL_06f899d341134e119357f1d8c91dd4cd",
            "value": "100%"
          }
        },
        "246f7bcacba7412c8f6ae94b1a02380b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86017395b8c249e6a74bdc180b56caf5",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a06fe6a0db2f4d0dbff46472ede37d52",
            "value": 553433881
          }
        },
        "4b24ec443a674c398d599bfd4a019033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62d6675e72174d938eecc3a7aa13bcd1",
            "placeholder": "​",
            "style": "IPY_MODEL_8535e0bb143945fd85416eb2a1dae43f",
            "value": " 528M/528M [00:07&lt;00:00, 86.1MB/s]"
          }
        },
        "e86d6914bbf24d5ba2e4bf5eac05bd02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c9a2cd9d0d42c3a1a09a55dc76173f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f899d341134e119357f1d8c91dd4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86017395b8c249e6a74bdc180b56caf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a06fe6a0db2f4d0dbff46472ede37d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62d6675e72174d938eecc3a7aa13bcd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8535e0bb143945fd85416eb2a1dae43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acybermind/Application-of-Transfer-Learning-on-Discremination-of-Leukemia-/blob/main/Transfer_Learning_Project_pre.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Application of Transfer Learning on Discremination of Leukemia**\n",
        "\n",
        "Recently, **machine learning** has played a crucial role in unearthing the hidden parts of various disciplines such as physics, neuroscience, and engineering. Its societal impacts will reach beyond our predictions in a couple of decades. **Deep learning**, a sophisticated machine learning technique, consists of neural networks simulating the behavior of any dynamic system. The constraints in biological sciences strengthen the importance of deep learning in hypothesizing and testing possible explanations about underpinning mechanisms of that phenomena. **The opportunity cost of minuscule imaging parts of cells and making decisions based on that imaging is very high**, and thanks to deep learning, we can overcome these constraints.\n",
        "\n",
        "Although network architecture and optimization techniques are some of the powerful primary weapons of deep learning, these weapons are ineffective for some problems in which researchers have technical limitations. At this point, **transfer learning** offers a solution with the help of gained knowledge of pre-trained models applied to similar issues. The success of transfer learning depends on how pre-trained models generalize the patterns vital for similar problems. Acquired knowledge from the models trained for object detection tasks, for example, is transferred to the disease detection tasks."
      ],
      "metadata": {
        "id": "nak8IJnJF4RM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi9_SbS6H-eP"
      },
      "source": [
        "## Required Libraries and Its Specific Functions for Performing Transfer Learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C17-S6r8IeYZ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "# print(\"PyTorch Version: \",torch.__version__)   # Be sure about having pytorch properly!\n",
        "# print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation for Training "
      ],
      "metadata": {
        "id": "-oAN_ZAhIsni"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dmDfex_Ip2b"
      },
      "source": [
        "# convert data to a normalized torch.FloatTensor\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(1200), # for the C_NMC datase to make it 300 since images are 450x450\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.Resize(224),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.RandomResizedCrop(1200), # for the C_NMC datase to make it 300 since images are 450x450\n",
        "                                      transforms.RandomRotation(30),\n",
        "                                      transforms.Resize(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to Drive "
      ],
      "metadata": {
        "id": "Cthnny7AJdCm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUIlaiHn5x_G",
        "outputId": "1d0fe64c-c4df-4893-de2e-f21c3924aa0a"
      },
      "source": [
        "drive.mount._DEBUG = True\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unset HISTFILE; export PS1=\"root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: \"\n",
            "bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
            "bash: no job control in this shell\n",
            "\u001b[01;34m/content\u001b[00m# root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: umount -f /content/drive || umount /content/drive; pkill -9 -x drive\n",
            "umount: /content/drive: no mount point specified.\n",
            "umount: /content/drive: no mount point specified.\n",
            "root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: pkill -9 -f /opt/google/drive/directoryprefetcher_binary\n",
            "root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: ( while `sleep 0.5`; do if [[ -d \"/content/drive\" && \"$(ls -A /content/drive)\" != \"\" ]]; then echo \"google.colab.drive MOUNTED\"; break; fi; done ) &\n",
            "[1] 1233\n",
            "root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: ( /opt/google/drive/drive --features=fuse_max_background:1000,max_read_qps:1000,max_write_qps:1000,max_operation_batch_size:15,max_parallel_push_task_instances:10,opendir_timeout_ms:120000,virtual_folders_omit_spaces:true,read_only_mode:false --inet_family=IPV4_ONLY --metadata_server_auth_uri=172.28.0.1:8009/computeMetadata/v1 --preferences=trusted_root_certs_file_path:/opt/google/drive/roots.pem,mount_point_path:/content/drive 2>&1 | grep --line-buffered -E \"Drive File Stream encountered a problem and has stopped|The domain policy has disabled Drive File Stream\"; echo \"drive EXITED\"; ) &\n",
            "[2] 1235\n",
            "root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: google.colab.drive MOUNTED\n",
            "fuser -kw \"/root/.config/Google/DriveFS/Logs/timeouts.txt\" ; rm -rf \"/root/.config/Google/DriveFS/Logs/timeouts.txt\"\n",
            "Specified filename /root/.config/Google/DriveFS/Logs/timeouts.txt does not exist.\n",
            "root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: nohup bash -c 'tail -n +0 -F \"/root/.config/Google/DriveFS/Logs/drive_fs.txt\" | python3 /opt/google/drive/drive-filter.py > \"/root/.config/Google/DriveFS/Logs/timeouts.txt\" ' < /dev/null > /dev/null 2>&1 &\n",
            "[3] 1411\n",
            "root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: nohup bash -c '/opt/google/drive/directoryprefetcher_binary -mountpoint=/content/drive' >> /root/.config/Google/DriveFS/Logs/dpb.txt 2>&1 &\n",
            "[4] 1414\n",
            "root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: disown -a\n",
            "root@5eb8afa60cf0-629dada5b567475eb4557b79f7c69708: exit\n",
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I9YMQfqVmQY"
      },
      "source": [
        "## If you want to use the **C_NMA** dataset, then skip to run the code below and run the subsequent one\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0cABa8rI1sJ"
      },
      "source": [
        "#### For the leukemia dataset\n",
        "\n",
        "data_dir= '/content/drive/MyDrive/Colab Notebooks/NeuroMatch_DL/Transfer_Learning/SN-AM'\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/val', transform=test_transforms)\n",
        "#defining classes\n",
        "classes=['ALL','MM'] \n",
        "\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 2\n",
        "# how many samples per batch to load\n",
        "batch_size = 32\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)   \n",
        "\n",
        "#torch.utils.data.WeightedRandomSampler(weights, num_samples, replacement=True, generator=None)\n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    sampler=train_sampler, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "    sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "    num_workers=num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_e3DjN2UrIv"
      },
      "source": [
        "### If you run the SN-AM dataset, then do not run the code below which is written for the C_NMC dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JGO2SbhJHZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e68e696-68a3-4d7e-a6b3-9d523f366079"
      },
      "source": [
        "# number of subprocesses to use for data loading\n",
        "num_workers = 2\n",
        "# how many samples per batch to load\n",
        "batch_size = 32\n",
        "\n",
        "data_dir= '/content/drive/MyDrive/Colab Notebooks/NeuroMatch_DL/Transfer_Learning/C_NMC'\n",
        "print(os.path.exists(data_dir))\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "valid_data = datasets.ImageFolder(data_dir + '/val', transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(data_dir + '/testing_data', transform=test_transforms)\n",
        "#defining classes\n",
        "classes=['all','hem'] \n",
        "\n",
        "# prepare data loaders (combine dataset and sampler)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QhuzoZhJIlX"
      },
      "source": [
        "# helper function to un-normalize and display an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0))) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "Yrbn_gbTJORT",
        "outputId": "51f16d78-ba8d-4378-874d-b51045303c57"
      },
      "source": [
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "print(dataiter)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() # convert images to numpy for display\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "# display 20 images\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "    ax.set_title(classes[labels[idx]])# Load the next batch\n",
        "batch_images, batch_labels = next(iter(train_loader))\n",
        "print('Batch size:', batch_images.shape)\n",
        "\n",
        "# Display the first image from the batch\n",
        "plt.imshow(batch_images[0].permute(1, 2, 0))\n",
        "plt.show()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f0abcc10ee0>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4dd932e5aa27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert images to numpy for display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOa9KTelJOPB"
      },
      "source": [
        "def save_model(epochs, model, optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Function to save the trained model to disk.\n",
        "    \"\"\"\n",
        "    torch.save({\n",
        "                'epoch': epochs,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, './model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX9JVxj2JOKu"
      },
      "source": [
        "# training\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    for data in train_loader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass\n",
        "        outputs = model(images)\n",
        "        # calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # calculate the accuracy\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        # update the optimizer parameters\n",
        "        optimizer.step()\n",
        "        \n",
        "                \n",
        "    # loss and accuracy for the complete epoch\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * (correct / total)\n",
        "    \n",
        "    return epoch_loss, epoch_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f53cNo_cJOHb"
      },
      "source": [
        "# for test and validation \n",
        "def test(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # forward pass\n",
        "            outputs = model(images)\n",
        "            # calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            # calculate the accuracy\n",
        "            total += labels.size(0)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "        \n",
        "    # loss and accuracy for the complete epoch\n",
        "    epoch_loss = running_loss / len(test_loader)\n",
        "    epoch_acc = 100. * (correct / total)\n",
        "    \n",
        "    return epoch_loss, epoch_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klxqTKbpJNxU"
      },
      "source": [
        "def save_plots(train_acc, valid_acc, test_acc, train_loss, valid_loss, test_loss):\n",
        "    \"\"\"\n",
        "    Function to save the loss and accuracy plots to disk.\n",
        "    \"\"\"\n",
        "    # create figure\n",
        "    fig = plt.figure(figsize=(18, 5))\n",
        "\n",
        "    # setting values to rows and column variables\n",
        "    rows = 1\n",
        "    columns = 2\n",
        "\n",
        "    # Adds a subplot at the 1st position\n",
        "    fig.add_subplot(rows, columns, 1)\n",
        "\n",
        "    plt.plot(train_acc,'-o')\n",
        "    plt.plot(valid_acc,'-o')\n",
        "    plt.plot(test_acc,'-o')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend(['Train','Valid','Test'])\n",
        "    plt.title('Train vs Valid vs Test Accuracy')\n",
        "\n",
        "    # Adds a subplot at the 2nd position\n",
        "    fig.add_subplot(rows, columns, 2)\n",
        "\n",
        "    plt.plot(train_loss,'-o')\n",
        "    plt.plot(valid_loss,'-o')\n",
        "    plt.plot(test_loss,'-o')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('losses')\n",
        "    plt.legend(['Train','Valid','Test'])\n",
        "    plt.title('Train vs Valid vs Test Losses')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtMp0NcOMBvN"
      },
      "source": [
        "def main():\n",
        "  # lists to keep track of losses and accuracies\n",
        "  train_loss, valid_loss, test_loss = [], [], []\n",
        "  train_acc, valid_acc, test_acc = [], [], []\n",
        "\n",
        "  # start the training\n",
        "  for epoch in range(epochs):\n",
        "      print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
        "      train_epoch_loss, train_epoch_acc = train(model, train_loader,optimizer, criterion)\n",
        "      valid_epoch_loss, valid_epoch_acc = test(model, valid_loader,criterion)\n",
        "      test_epoch_loss, test_epoch_acc = test(model, test_loader,criterion)\n",
        "      train_loss.append(train_epoch_loss)\n",
        "      valid_loss.append(valid_epoch_loss)\n",
        "      test_loss.append(test_epoch_loss)\n",
        "      train_acc.append(train_epoch_acc)\n",
        "      valid_acc.append(valid_epoch_acc)\n",
        "      test_acc.append(test_epoch_acc)\n",
        "      print(f\"Training loss: {train_epoch_loss:.3f} | Training acc: {train_epoch_acc:.3f}\")\n",
        "      print(f\"Validation loss: {valid_epoch_loss:.3f} | Validation acc: {valid_epoch_acc:.3f}\")\n",
        "      print(f\"Test loss: {test_epoch_loss:.3f} | Test acc: {test_epoch_acc:.3f}\")\n",
        "      print('-*-'*20)\n",
        "  # save the trained model weights\n",
        "  save_model(epochs, model, optimizer, criterion)\n",
        "  print('TRAINING COMPLETE')\n",
        "  # save the loss and accuracy plots\n",
        "  save_plots(train_acc, valid_acc, test_acc, train_loss, valid_loss, test_loss )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q9ioL8oK-Un"
      },
      "source": [
        "# The First Pre-trained Model     ----->     VGG16\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "47e97caf5b68455886482a8f7550236f",
            "c999b6ca64754464af78adf60f2de7a9",
            "246f7bcacba7412c8f6ae94b1a02380b",
            "4b24ec443a674c398d599bfd4a019033",
            "e86d6914bbf24d5ba2e4bf5eac05bd02",
            "17c9a2cd9d0d42c3a1a09a55dc76173f",
            "06f899d341134e119357f1d8c91dd4cd",
            "86017395b8c249e6a74bdc180b56caf5",
            "a06fe6a0db2f4d0dbff46472ede37d52",
            "62d6675e72174d938eecc3a7aa13bcd1",
            "8535e0bb143945fd85416eb2a1dae43f"
          ]
        },
        "id": "vdop_tsILJ9s",
        "outputId": "aab11955-71f9-47f6-9eab-626284038cf3"
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "# model   # if you want to see the architecture uncomment this line "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47e97caf5b68455886482a8f7550236f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfkgaILjLPSd"
      },
      "source": [
        "# Freeze parameters so we don't backprop through them \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# Newly created modules have require_grad=True by default\n",
        "num_features = model.classifier[6].in_features\n",
        "features = list(model.classifier.children())[:-1] # Remove last layer\n",
        "features.extend([nn.Linear(num_features, len(classes))]) # Add our layer with 4 outputs\n",
        "model.classifier = nn.Sequential(*features) # Replace the model classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFajMv3aLUEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca14c5d1-cc4f-475f-b3ec-9bb8a3559962"
      },
      "source": [
        "from torch.optim import Adam\n",
        " \n",
        "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9) \n",
        "\n",
        "# criterion = nn.NLLLoss()\n",
        "# optimizer = optim.Adam(model.classifier.parameters(), lr=0.0005) \n",
        "epochs = 10\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO]: Epoch 1 of 10\n",
            "Training loss: 0.486 | Training acc: 94.500\n",
            "Validation loss: 28.533 | Validation acc: 35.988\n",
            "Test loss: 29.507 | Test acc: 33.333\n",
            "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
            "[INFO]: Epoch 2 of 10\n",
            "Training loss: 7.579 | Training acc: 81.271\n",
            "Validation loss: 44.405 | Validation acc: 35.988\n",
            "Test loss: 45.950 | Test acc: 33.333\n",
            "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
            "[INFO]: Epoch 3 of 10\n",
            "Training loss: 11.255 | Training acc: 77.786\n",
            "Validation loss: 45.377 | Validation acc: 35.988\n",
            "Test loss: 44.893 | Test acc: 33.333\n",
            "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
            "[INFO]: Epoch 4 of 10\n",
            "Training loss: 11.190 | Training acc: 77.999\n",
            "Validation loss: 44.814 | Validation acc: 35.988\n",
            "Test loss: 43.892 | Test acc: 33.333\n",
            "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
            "[INFO]: Epoch 5 of 10\n",
            "Training loss: 10.935 | Training acc: 78.331\n",
            "Validation loss: 43.249 | Validation acc: 35.988\n",
            "Test loss: 43.529 | Test acc: 33.333\n",
            "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
            "[INFO]: Epoch 6 of 10\n",
            "Training loss: 10.682 | Training acc: 78.307\n",
            "Validation loss: 42.669 | Validation acc: 35.988\n",
            "Test loss: 43.419 | Test acc: 33.333\n",
            "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
            "[INFO]: Epoch 7 of 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d82y5v-yMV7k"
      },
      "source": [
        "# The Second Pre-trained Model     ----->     DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWmXPypDMg96"
      },
      "source": [
        "model = models.densenet121(pretrained=True)\n",
        "# model   # if you want to see the architecture uncomment this line  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P39Gk38ym5q"
      },
      "source": [
        "# Freeze parameters so we don't backprop through them \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.classifier = nn.Sequential(nn.Linear(1024, 512),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.5),\n",
        "                                 nn.Linear(512,256),\n",
        "                                 nn.Linear(256, 2),\n",
        "                                 nn.LogSoftmax(dim=1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZLABW6rMg7h"
      },
      "source": [
        "from torch.optim import Adam\n",
        " \n",
        "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9) \n",
        "\n",
        "# criterion = nn.NLLLoss()\n",
        "# optimizer = optim.Adam(model.classifier.parameters(), lr=0.0005) \n",
        "epochs = 10\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5naKZXk6NJay"
      },
      "source": [
        "# The Third Pre-trained Model     ----->     GoogleNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hh_XzdTMgz9"
      },
      "source": [
        "model = models.googlenet(pretrained=True)\n",
        "# model   # if you want to see the architecture uncomment this line "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVGN9woFyuF8"
      },
      "source": [
        "# Freeze parameters so we don't backprop through them \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Sequential(nn.Linear(1024, 512),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(0.6), # it was 0.5\n",
        "                                 nn.Linear(512,2),\n",
        "                                 nn.LogSoftmax(dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JWTp-juMgxV"
      },
      "source": [
        "from torch.optim import Adam\n",
        " \n",
        "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9) \n",
        "\n",
        "# criterion = nn.NLLLoss()\n",
        "# optimizer = optim.Adam(model.classifier.parameters(), lr=0.0005) \n",
        "epochs = 10\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}